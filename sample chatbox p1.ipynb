{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from http.client import responses\n",
    "\n",
    "from sympy.polys.polyoptions import Auto\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-07T05:56:51.772637600Z",
     "start_time": "2026-02-07T05:56:38.653906200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name=\"facebook/blenderbot-400M-distill\"\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)"
   ],
   "id": "5ba6506f0eb109f2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie model.shared.weight to model.decoder.embed_tokens.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-07T05:56:51.827447900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_with_box():\n",
    "    while True:\n",
    "        input_text=input(\"YOU \")\n",
    "    if input_text.lower() in ['quit','exit','bye']:\n",
    "        print(\"Chatbox: Goodbye!\")\n",
    "\n",
    "    inputs=tokenizer.encode(input_text)\n",
    "    outputs=model.genrate(inputs,max_new_token=150)\n",
    "    response=tokenizer.decode(outputs[00],skip_special_tokens=True).strip()\n",
    "    print(response)\n",
    "chat_with_box()\n"
   ],
   "id": "2ef98fffe72daa5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "model_name='google/flan-t5-base'\n",
    "tokenizer=AutoTokenizer.from_pretrained(model_name)\n",
    "model=AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ],
   "id": "89a0ba575895c61c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def chat_with_another_bot():\n",
    "    while True:\n",
    "\n",
    "        input_text = input(\"You: \")\n",
    "\n",
    "\n",
    "        if input_text.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "            print(\"Chatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "        print(\"Chatbot:\", response)\n",
    "\n",
    "\n",
    "chat_with_another_bot()\n",
    "\n"
   ],
   "id": "9136b914a93d97e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sentencepiece\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ],
   "id": "7cd3bc3b58ffe054",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fad064a13d4ad3e6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
